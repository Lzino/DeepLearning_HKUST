{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(777) \n",
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n",
    "char_set = list(set (sentence)) #index -> char\n",
    "char_dic = {c:i for i , c in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_size = len(char_set) #RNN input size\n",
    "num_classes = len(char_set)\n",
    "batch_size = 1\n",
    "sequence_length = 10\n",
    "learning_rate = 0.1\n",
    "rnn_hidden_size = len(char_set)\n",
    "data_dim = len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan - -> f you want\n",
      "1 f you want - ->  you want \n",
      "2  you want  - -> you want t\n",
      "3 you want t - -> ou want to\n",
      "4 ou want to - -> u want to \n",
      "5 u want to  - ->  want to b\n",
      "6  want to b - -> want to bu\n",
      "7 want to bu - -> ant to bui\n",
      "8 ant to bui - -> nt to buil\n",
      "9 nt to buil - -> t to build\n",
      "10 t to build - ->  to build \n",
      "11  to build  - -> to build a\n",
      "12 to build a - -> o build a \n",
      "13 o build a  - ->  build a s\n",
      "14  build a s - -> build a sh\n",
      "15 build a sh - -> uild a shi\n",
      "16 uild a shi - -> ild a ship\n",
      "17 ild a ship - -> ld a ship,\n",
      "18 ld a ship, - -> d a ship, \n",
      "19 d a ship,  - ->  a ship, d\n",
      "20  a ship, d - -> a ship, do\n",
      "21 a ship, do - ->  ship, don\n",
      "22  ship, don - -> ship, don'\n",
      "23 ship, don' - -> hip, don't\n",
      "24 hip, don't - -> ip, don't \n",
      "25 ip, don't  - -> p, don't d\n",
      "26 p, don't d - -> , don't dr\n",
      "27 , don't dr - ->  don't dru\n",
      "28  don't dru - -> don't drum\n",
      "29 don't drum - -> on't drum \n",
      "30 on't drum  - -> n't drum u\n",
      "31 n't drum u - -> 't drum up\n",
      "32 't drum up - -> t drum up \n",
      "33 t drum up  - ->  drum up p\n",
      "34  drum up p - -> drum up pe\n",
      "35 drum up pe - -> rum up peo\n",
      "36 rum up peo - -> um up peop\n",
      "37 um up peop - -> m up peopl\n",
      "38 m up peopl - ->  up people\n",
      "39  up people - -> up people \n",
      "40 up people  - -> p people t\n",
      "41 p people t - ->  people to\n",
      "42  people to - -> people tog\n",
      "43 people tog - -> eople toge\n",
      "44 eople toge - -> ople toget\n",
      "45 ople toget - -> ple togeth\n",
      "46 ple togeth - -> le togethe\n",
      "47 le togethe - -> e together\n",
      "48 e together - ->  together \n",
      "49  together  - -> together t\n",
      "50 together t - -> ogether to\n",
      "51 ogether to - -> gether to \n",
      "52 gether to  - -> ether to c\n",
      "53 ether to c - -> ther to co\n",
      "54 ther to co - -> her to col\n",
      "55 her to col - -> er to coll\n",
      "56 er to coll - -> r to colle\n",
      "57 r to colle - ->  to collec\n",
      "58  to collec - -> to collect\n",
      "59 to collect - -> o collect \n",
      "60 o collect  - ->  collect w\n",
      "61  collect w - -> collect wo\n",
      "62 collect wo - -> ollect woo\n",
      "63 ollect woo - -> llect wood\n",
      "64 llect wood - -> lect wood \n",
      "65 lect wood  - -> ect wood a\n",
      "66 ect wood a - -> ct wood an\n",
      "67 ct wood an - -> t wood and\n",
      "68 t wood and - ->  wood and \n",
      "69  wood and  - -> wood and d\n",
      "70 wood and d - -> ood and do\n",
      "71 ood and do - -> od and don\n",
      "72 od and don - -> d and don'\n",
      "73 d and don' - ->  and don't\n",
      "74  and don't - -> and don't \n",
      "75 and don't  - -> nd don't a\n",
      "76 nd don't a - -> d don't as\n",
      "77 d don't as - ->  don't ass\n",
      "78  don't ass - -> don't assi\n",
      "79 don't assi - -> on't assig\n",
      "80 on't assig - -> n't assign\n",
      "81 n't assign - -> 't assign \n",
      "82 't assign  - -> t assign t\n",
      "83 t assign t - ->  assign th\n",
      "84  assign th - -> assign the\n",
      "85 assign the - -> ssign them\n",
      "86 ssign them - -> sign them \n",
      "87 sign them  - -> ign them t\n",
      "88 ign them t - -> gn them ta\n",
      "89 gn them ta - -> n them tas\n",
      "90 n them tas - ->  them task\n",
      "91  them task - -> them tasks\n",
      "92 them tasks - -> hem tasks \n",
      "93 hem tasks  - -> em tasks a\n",
      "94 em tasks a - -> m tasks an\n",
      "95 m tasks an - ->  tasks and\n",
      "96  tasks and - -> tasks and \n",
      "97 tasks and  - -> asks and w\n",
      "98 asks and w - -> sks and wo\n",
      "99 sks and wo - -> ks and wor\n",
      "100 ks and wor - -> s and work\n",
      "101 s and work - ->  and work,\n",
      "102  and work, - -> and work, \n",
      "103 and work,  - -> nd work, b\n",
      "104 nd work, b - -> d work, bu\n",
      "105 d work, bu - ->  work, but\n",
      "106  work, but - -> work, but \n",
      "107 work, but  - -> ork, but r\n",
      "108 ork, but r - -> rk, but ra\n",
      "109 rk, but ra - -> k, but rat\n",
      "110 k, but rat - -> , but rath\n",
      "111 , but rath - ->  but rathe\n",
      "112  but rathe - -> but rather\n",
      "113 but rather - -> ut rather \n",
      "114 ut rather  - -> t rather t\n",
      "115 t rather t - ->  rather te\n",
      "116  rather te - -> rather tea\n",
      "117 rather tea - -> ather teac\n",
      "118 ather teac - -> ther teach\n",
      "119 ther teach - -> her teach \n",
      "120 her teach  - -> er teach t\n",
      "121 er teach t - -> r teach th\n",
      "122 r teach th - ->  teach the\n",
      "123  teach the - -> teach them\n",
      "124 teach them - -> each them \n",
      "125 each them  - -> ach them t\n",
      "126 ach them t - -> ch them to\n",
      "127 ch them to - -> h them to \n",
      "128 h them to  - ->  them to l\n",
      "129  them to l - -> them to lo\n",
      "130 them to lo - -> hem to lon\n",
      "131 hem to lon - -> em to long\n",
      "132 em to long - -> m to long \n",
      "133 m to long  - ->  to long f\n",
      "134  to long f - -> to long fo\n",
      "135 to long fo - -> o long for\n",
      "136 o long for - ->  long for \n",
      "137  long for  - -> long for t\n",
      "138 long for t - -> ong for th\n",
      "139 ong for th - -> ng for the\n",
      "140 ng for the - -> g for the \n",
      "141 g for the  - ->  for the e\n",
      "142  for the e - -> for the en\n",
      "143 for the en - -> or the end\n",
      "144 or the end - -> r the endl\n",
      "145 r the endl - ->  the endle\n",
      "146  the endle - -> the endles\n",
      "147 the endles - -> he endless\n",
      "148 he endless - -> e endless \n",
      "149 e endless  - ->  endless i\n",
      "150  endless i - -> endless im\n",
      "151 endless im - -> ndless imm\n",
      "152 ndless imm - -> dless imme\n",
      "153 dless imme - -> less immen\n",
      "154 less immen - -> ess immens\n",
      "155 ess immens - -> ss immensi\n",
      "156 ss immensi - -> s immensit\n",
      "157 s immensit - ->  immensity\n",
      "158  immensity - -> immensity \n",
      "159 immensity  - -> mmensity o\n",
      "160 mmensity o - -> mensity of\n",
      "161 mensity of - -> ensity of \n",
      "162 ensity of  - -> nsity of t\n",
      "163 nsity of t - -> sity of th\n",
      "164 sity of th - -> ity of the\n",
      "165 ity of the - -> ty of the \n",
      "166 ty of the  - -> y of the s\n",
      "167 y of the s - ->  of the se\n",
      "168  of the se - -> of the sea\n",
      "169 of the sea - -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0,len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    print(i, x_str, '- ->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32,[None, sequence_length]) #X one-hot\n",
    "Y = tf.placeholder(tf.int32,[None, sequence_length]) #Y Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 10, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "print(X_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    cell = rnn.BasicLSTMCell(rnn_hidden_size, state_is_tuple = True)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi_cells = rnn.MultiRNNCell([lstm_cell() for _ in range(2)], state_is_tuple = True)\n",
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_for_fc  = tf.reshape(outputs, [-1, rnn_hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_w = tf.get_variable(\"softmax_w\", [rnn_hidden_size, num_classes])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [num_classes])\n",
    "softmax_outputs = tf.matmul(outputs, softmax_w) + softmax_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshape out for squence loss\n",
    "outputs = tf.reshape(softmax_outputs, [batch_size, sequence_length, num_classes])\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets = Y, weights= weights)\n",
    "mean_loss = tf.reduce_mean(sequence_loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(mean_loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2275):\n",
    "        _, l, results = sess.run(\n",
    "            [train_op, mean_loss, outputs], feed_dict={X: dataX, Y: dataY})\n",
    "        for j , result in enumerate(results):\n",
    "            index = np.argmax(result, axis = 1)\n",
    "            #print(i , j , ''.join([char_set[t] for t in index]), l)\n",
    "            \n",
    "    results = sess.run(outputs, feed_dict = {X : dataX})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis = 1)\n",
    "        if j is 0 : # print all for the first result to make a sentence\n",
    "            print(''.join([char_set[t] for t in index]), end = '')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end = '')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 154 kkkkkkkkkk 3.24344\\n0 155 kkkk,,kkkk 3.24344\\n0 156 k,,,,kkkkk 3.24344\\n0 157 kkkkkkkkk, 3.24344\\n0 158 kkkkkkkk,, 3.24344\\n0 159 kkkkkkk,,k 3.24344\\n0 160 kkklll,,kk 3.24344\\n0 161 kkkkk,kkkk 3.24344\\n0 162 kkkkkkkkkk 3.24344\\n0 163 kkk,kkkkkk 3.24344\\n0 164 kk,,kkkkkk 3.24344\\n0 165 k,kkkkkkkk 3.24344\\n0 166 kkkkkkkkkk 3.24344\\n0 167 kkkkkkkkkk 3.24344\\n0 168 kkkkkkkk,, 3.24344\\n0 169 kkkkkkk,,, 3.24344\\n\\n.....\\n2274 154 ecs immens 0.228647\\n2274 155 rs immensi 0.228647\\n2274 156 s immensit 0.228647\\n2274 157 sammensity 0.228647\\n2274 158 tmmensity  0.228647\\n2274 159 gmensity o 0.228647\\n2274 160  ensity of 0.228647\\n2274 161  nsity of  0.228647\\n2274 162 rsity of t 0.228647\\n2274 163 dity of th 0.228647\\n2274 164 sgy of the 0.228647\\n2274 165 gy of the  0.228647\\n2274 166   of the s 0.228647\\n2274 167 oof the se 0.228647\\n2274 168 tf the sea 0.228647\\n2274 169   the sea. 0.228647\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0 154 kkkkkkkkkk 3.24344\n",
    "0 155 kkkk,,kkkk 3.24344\n",
    "0 156 k,,,,kkkkk 3.24344\n",
    "0 157 kkkkkkkkk, 3.24344\n",
    "0 158 kkkkkkkk,, 3.24344\n",
    "0 159 kkkkkkk,,k 3.24344\n",
    "0 160 kkklll,,kk 3.24344\n",
    "0 161 kkkkk,kkkk 3.24344\n",
    "0 162 kkkkkkkkkk 3.24344\n",
    "0 163 kkk,kkkkkk 3.24344\n",
    "0 164 kk,,kkkkkk 3.24344\n",
    "0 165 k,kkkkkkkk 3.24344\n",
    "0 166 kkkkkkkkkk 3.24344\n",
    "0 167 kkkkkkkkkk 3.24344\n",
    "0 168 kkkkkkkk,, 3.24344\n",
    "0 169 kkkkkkk,,, 3.24344\n",
    "\n",
    ".....\n",
    "2274 154 ecs immens 0.228647\n",
    "2274 155 rs immensi 0.228647\n",
    "2274 156 s immensit 0.228647\n",
    "2274 157 sammensity 0.228647\n",
    "2274 158 tmmensity  0.228647\n",
    "2274 159 gmensity o 0.228647\n",
    "2274 160  ensity of 0.228647\n",
    "2274 161  nsity of  0.228647\n",
    "2274 162 rsity of t 0.228647\n",
    "2274 163 dity of th 0.228647\n",
    "2274 164 sgy of the 0.228647\n",
    "2274 165 gy of the  0.228647\n",
    "2274 166   of the s 0.228647\n",
    "2274 167 oof the se 0.228647\n",
    "2274 168 tf the sea 0.228647\n",
    "2274 169   the sea. 0.228647\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
